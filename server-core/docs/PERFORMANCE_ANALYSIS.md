# Performance Bottleneck Analysis: server-core/src

## Executive Summary

Analysis of `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src` reveals **6 critical performance issues** affecting hot paths in query processing, event dispatching, and component lifecycle management. These issues could significantly impact throughput and latency in high-volume scenarios.

---

## Issue 1: Excessive RwLock Acquisitions in Event Processing Hot Path

**Severity**: HIGH
**Impact**: Lock contention on every event, cascading across priority queue operations
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 160-162, 690-732)
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/reactions/manager.rs` (lines 478-516)

### Problem

The query result set is protected by an `Arc<RwLock<Vec<serde_json::Value>>>` and is **locked on every single event** during processing:

```rust
// In queries/manager.rs, lines 690-732 (event processing loop)
let mut result_set = current_results.write().await;  // LOCK #1
for result in &converted_results {
    if let Some(change_type) = result.get("type").and_then(|t| t.as_str()) {
        match change_type {
            "ADD" => {
                if let Some(data) = result.get("data") {
                    result_set.push(data.clone());  // EXPENSIVE CLONE
                }
            }
            "DELETE" => {
                if let Some(data) = result.get("data") {
                    result_set.retain(|item| item != data);  // O(n) on every delete
                }
            }
            "UPDATE" => {
                if let Some(before), Some(after)) = (...) {
                    if let Some(pos) = result_set.iter().position(...) {  // O(n) scan
                        result_set[pos] = after.clone();  // EXPENSIVE CLONE
                    }
                }
            }
```

Additionally, `get_current_results()` clones the entire result set on each read:

```rust
// In queries/manager.rs, lines 161-163
pub async fn get_current_results(&self) -> Vec<serde_json::Value> {
    self.current_results.read().await.clone()  // FULL CLONE
}
```

### Performance Impact

- **Per-event overhead**: 1 RwLock write acquisition + Vec mutations (O(n) for deletes/updates)
- **Full clone overhead**: Every `get_current_results()` call clones entire result set (potentially thousands of items)
- **Lock contention**: All queries compete for the single RwLock, especially in high-volume scenarios
- **Cascading locks**: Priority queue drain at shutdown requires full scan while lock is held

**Example with 10,000 events/sec and 100-item result set**:
- 10,000 lock acquisitions/sec
- 10,000+ Vec clones (if results are accessed frequently)
- O(n) operations on each update/delete
- Total impact: ~100ms+ of lock contention per second at production scale

### Suggested Optimization

Replace `Arc<RwLock<Vec<T>>>` with a lock-free approach:

1. **Use `Arc<DashMap<K, V>>` or `crossbeam::queue::SegQueue`**: Better concurrency for updates
2. **Separate read/write paths**: Use `Arc<Mutex<Vec<T>>>` with fine-grained locking sections
3. **Avoid full clones**: Return references or iterators with short-lived locks
4. **Implement versioning**: Use atomic version numbers for change detection without cloning

```rust
// Better approach using DashMap
use dashmap::DashMap;

pub struct DrasiQuery {
    current_results: Arc<DashMap<String, serde_json::Value>>,  // Lock-free per item
}

pub async fn update_results(&self, changes: Vec<QueryChange>) {
    for change in changes {
        match change {
            Add { key, value } => {
                self.current_results.insert(key, value);  // No global lock
            }
            Delete { key } => {
                self.current_results.remove(&key);  // No global lock
            }
            Update { key, value } => {
                self.current_results.alter(&key, |_, _| value);  // Scoped lock
            }
        }
    }
}
```

---

## Issue 2: Repeated HashMap/BTreeMap Clones in Manager Classes

**Severity**: MEDIUM-HIGH
**Impact**: Excessive allocations during component lookups and lifecycle operations
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/sources/manager.rs` (lines 248-264, 385-423)
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 1094-1110)
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/reactions/manager.rs` (lines 451-467)

### Problem

Manager classes create full snapshots of component HashMaps on every listing operation:

```rust
// In sources/manager.rs, lines 248-264
pub async fn list_sources(&self) -> Vec<(String, ComponentStatus)> {
    let sources: Vec<(String, Arc<dyn Source>)> = {
        let sources = self.sources.read().await;
        sources
            .iter()
            .map(|(id, source)| (id.clone(), source.clone()))  // CLONE ALL
            .collect()
    };

    let mut result = Vec::new();
    for (id, source) in sources {
        let status = source.status().await;
        result.push((id, status));
    }
    result
}
```

Similar pattern in `start_all()` and `stop_all()`:

```rust
// In sources/manager.rs, lines 385-423
pub async fn start_all(&self) -> Result<()> {
    let sources: Vec<Arc<dyn Source>> = {
        let sources = self.sources.read().await;
        sources.values().cloned().collect()  // CLONE ALL VALUES
    };

    let mut failed_sources = Vec::new();
    for source in sources {  // ITERATE CLONES
        let config = source.get_config();
        // ...
    }
}
```

### Performance Impact

- **Allocation overhead**: Each list/start/stop operation allocates a new Vec and clones all Arc pointers
- **Cache misses**: Cloned Arcs point to same data, but iteration is cache-unfriendly
- **Repeated access pattern**: If called frequently (e.g., health checks every 100ms with 100 sources), creates 1000+ Arc clones per second

### Suggested Optimization

Use iterators instead of collecting into intermediate Vecs:

```rust
pub async fn list_sources(&self) -> Vec<(String, ComponentStatus)> {
    let sources = self.sources.read().await;

    // Collect while holding read lock only as needed
    let mut result = Vec::with_capacity(sources.len());
    for (id, source) in sources.iter() {
        // Release lock for await
        let id_clone = id.clone();
        let source_clone = Arc::clone(source);
        drop(sources);  // Release read lock early

        let status = source_clone.status().await;
        result.push((id_clone, status));

        // Re-acquire if not last
        if result.len() < sources.len() {
            let sources = self.sources.read().await;
        }
    }
    result
}

// Or for start_all - iterate without collecting first:
pub async fn start_all(&self) -> Result<()> {
    let sources_snapshot = {
        let sources = self.sources.read().await;
        sources
            .iter()
            .map(|(id, source)| (id.clone(), Arc::clone(source)))
            .collect::<Vec<_>>()  // Only clone Arc pointers, not configs
    };

    for (id, source) in sources_snapshot {
        // Process each...
    }
}
```

---

## Issue 3: O(n) Vector Operations Without Batch Optimization

**Severity**: MEDIUM
**Impact**: Slow result set updates on high-cardinality queries
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 703-704, 718)

### Problem

Result set management uses inefficient Vec operations:

```rust
// Issue A: O(n) retain on delete (lines 702-705)
"DELETE" => {
    if let Some(data) = result.get("data") {
        result_set.retain(|item| item != data);  // O(n) full scan + equality check
    }
}

// Issue B: O(n) position search on update (lines 711-720)
"UPDATE" => {
    if let Some(pos) = result_set.iter().position(|item| item == before) {  // O(n)
        result_set[pos] = after.clone();
    }
}

// Issue C: String cloning in result conversion (lines 644-688)
.map(|ctx| match ctx {
    QueryPartEvaluationContext::Adding { after } => {
        serde_json::json!({
            "type": "ADD",
            "data": convert_query_variables_to_json(after)  // O(k) where k = variable count
        })
    }
    // ... 6 more variants each with allocations
}).collect()  // Collects into Vec, allocates
```

### Performance Impact

- **Delete operation**: O(n) where n = result set size. 10,000 result items = 10,000+ comparisons per delete
- **Update operation**: O(n) scan + O(1) replace but loses original index
- **String allocations**: `convert_query_variables_to_json()` creates strings from integers/floats unnecessarily
- **Cascading effect**: Events often batch operations; delete + add = 2 O(n) scans

### Suggested Optimization

1. **Use indexed data structure**: Replace Vec with IndexMap or BTreeMap keyed by unique identifier
2. **Batch operations**: Collect updates before applying to result set
3. **Avoid string conversions**: Keep numeric types as JSON numbers, not strings

```rust
// Better: Use indexmap for O(1) lookups
use indexmap::IndexMap;

pub struct DrasiQuery {
    current_results: Arc<RwLock<IndexMap<String, serde_json::Value>>>,
    // ... key is stable identifier from query result
}

// In event processor
match change_type {
    "ADD" => {
        if let Some(key) = result.get("key") {  // Get stable key
            result_set.insert(key.as_str().unwrap().to_string(), data.clone());  // O(1)
        }
    }
    "DELETE" => {
        if let Some(key) = result.get("key") {
            result_set.remove(key.as_str().unwrap());  // O(1)
        }
    }
    "UPDATE" => {
        if let Some(key) = result.get("key") {
            result_set.insert(key.as_str().unwrap().to_string(), data.clone());  // O(1)
        }
    }
}

// Avoid string conversions for numbers
fn convert_variable_value_to_json(value: &VariableValue) -> serde_json::Value {
    match value {
        VariableValue::Float(f) => {
            if f.is_finite() {
                serde_json::json!(*f)  // Keep as JSON number
            } else {
                serde_json::Value::Null
            }
        }
        VariableValue::Integer(i) => serde_json::json!(*i),  // Keep as JSON number
        // ... rest
    }
}
```

---

## Issue 4: String Allocation Spam in Message Formatting

**Severity**: MEDIUM
**Impact**: Memory churn and allocator pressure
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 186, 248, 405-410, 508-509, 559)
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/channels/dispatcher.rs` (lines 265-269)

### Problem

Excessive string allocations in logging and message construction:

```rust
// Issue A: message.Some("Starting query".to_string()) (line 186)
let event = ComponentEvent {
    component_id: self.base.config.id.clone(),
    component_type: ComponentType::Query,
    status: ComponentStatus::Starting,
    timestamp: chrono::Utc::now(),
    message: Some("Starting query".to_string()),  // Unnecessary .to_string()
};

// Issue B: format! in metadata (lines 405-410)
let mut metadata = HashMap::new();
metadata.insert(
    "control_signal".to_string(),  // Allocates new String
    serde_json::json!("bootstrapStarted"),
);
metadata.insert(
    "source_count".to_string(),  // Another allocation
    serde_json::json!(bootstrap_channels.len()),
);

// Issue C: Repeated in bootstrap loop (line 438+)
// Same pattern repeats for "control_signal", "source_count" etc.

// Issue D: Log messages with context cloning (throughout)
log::warn!(
    "Broadcast receiver lagged by {} messages",
    n  // Good practice, but n is printed multiple times
);
```

### Performance Impact

- **Per-message overhead**: HashMap insertion requires String allocation for keys
- **Repeated keys**: Same keys ("control_signal", "source_count") allocated multiple times
- **Metadata spam**: Every result includes metadata HashMap with allocations
- **Total**: At 10,000 events/sec, 50,000+ string allocations/sec just for keys

### Suggested Optimization

1. **Use `&'static str` for static strings**: Avoid allocations for known strings
2. **Use string interning**: Reuse common strings via lazy_static or similar
3. **Use enum for metadata keys**: Type-safe, zero-allocation alternative

```rust
// Better: Use static strings
let event = ComponentEvent {
    component_id: self.base.config.id.clone(),
    component_type: ComponentType::Query,
    status: ComponentStatus::Starting,
    timestamp: chrono::Utc::now(),
    message: Some("Starting query"),  // &'static str, no allocation
};

// Better: Use enum + hashmap with interned values
use std::sync::OnceLock;

fn control_signal_key() -> &'static str {
    "control_signal"  // Reuse same string
}

fn source_count_key() -> &'static str {
    "source_count"
}

let mut metadata = HashMap::new();
metadata.insert(
    control_signal_key(),  // Already interned
    serde_json::json!("bootstrapStarted"),
);

// Even better: Use a dedicated metadata struct with typed fields
#[derive(Serialize)]
struct QueryMetadata {
    source_id: String,
    processed_by: &'static str,
    result_count: usize,
    control_signal: Option<&'static str>,
    source_count: Option<usize>,
}
```

---

## Issue 5: Multiple RwLock Acquisitions Per Manager Operation

**Severity**: MEDIUM
**Impact**: Lock contention during component lifecycle operations
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/sources/manager.rs` (lines 201-205, 313-315, 298-300)
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 928-930, 1014-1025)

### Problem

Operations acquire the same RwLock multiple times unnecessarily:

```rust
// In sources/manager.rs, lines 296-340 (update_source)
pub async fn update_source(&self, id: String, config: SourceConfig) -> Result<()> {
    let source = {
        let sources = self.sources.read().await;  // LOCK #1
        sources.get(&id).cloned()
    };

    if let Some(source) = source {
        // ... stop source ...

        let source = {
            let sources = self.sources.read().await;  // LOCK #2 - same map
            sources.get(&id).cloned()
        };
        // ... more work ...
    }
}

// In queries/manager.rs, lines 1013-1050 (update_query)
pub async fn update_query(&self, id: String, config: QueryConfig) -> Result<()> {
    let (query, was_running) = {
        let queries = self.queries.read().await;  // LOCK #1
        let query = queries.get(&id).cloned();
        if let Some(ref q) = query {
            let status = q.status().await;
            let was_running = matches!(status, ComponentStatus::Running | ComponentStatus::Starting);
            (query, was_running)
        } else {
            return Err(...);
        }
    };

    if let Some(query) = query {
        if was_running {
            self.stop_query(id.clone()).await?;  // May call stop internally

            let status = query.status().await;
            is_operation_valid(&status, &Operation::Update)?;
        } else {
            let status = query.status().await;  // LOCK-INDEPENDENT
            is_operation_valid(&status, &Operation::Update)?;
        }

        self.delete_query(id.clone()).await?;  // LOCK #2 within method
        self.add_query(config).await?;         // LOCK #3 within method

        if was_running {
            self.start_query(id).await?;       // LOCK #4 within method
        }
    }
}
```

### Performance Impact

- **Lock reacquisition**: Same lock acquired 2+ times in sequence
- **Blocking operations**: Each `await` on status() may trigger async work while lock could be held
- **Nested lock calls**: `update_query` calls `delete_query` + `add_query` which each acquire their own locks
- **Serialization**: Multiple sequential lock acquisitions serialize operations that could be batched

### Suggested Optimization

1. **Hold lock across related operations**: Reduce acquisitions from N to 1
2. **Extract internal methods**: Separate locked vs unlocked code paths
3. **Batch operations**: Group reads/writes to minimize lock hold time

```rust
// Better: Consolidate lock acquisitions
pub async fn update_query(&self, id: String, config: QueryConfig) -> Result<()> {
    // Single lock acquisition for all reads
    let (query, was_running) = {
        let queries = self.queries.read().await;
        let query = queries.get(&id).cloned()
            .ok_or_else(|| anyhow::anyhow!("Query not found"))?;

        let status = query.status().await;
        let was_running = matches!(status, ComponentStatus::Running | ComponentStatus::Starting);
        (query, was_running)
    };

    // Now operate without holding lock
    if was_running {
        query.stop().await?;  // Can't use manager method - would deadlock
    }

    // Validate status
    let status = query.status().await;
    is_operation_valid(&status, &Operation::Update)?;

    // Perform update with single write lock
    {
        let mut queries = self.queries.write().await;  // ONE LOCK for both remove + insert
        queries.remove(&id);
        let new_query = DrasiQuery::new(config, self.event_tx.clone())?;
        queries.insert(id.clone(), Arc::new(new_query));
    }

    if was_running {
        self.start_query(id).await?;
    }
}
```

---

## Issue 6: Unbounded Task Spawning in Bootstrap Processing

**Severity**: MEDIUM
**Impact**: Task explosion and executor starvation in high-fanout scenarios
**Affected Files**:
- `/Users/allenjones/dev/agentofreality/drasi/drasi-core/server-core/src/queries/manager.rs` (lines 451, 575)

### Problem

Bootstrap processing spawns one task per source without concurrency limits:

```rust
// In queries/manager.rs, lines 433-543
for (source_id, mut bootstrap_rx) in bootstrap_channels {
    // ...spawn one task per source without limit
    tokio::spawn(async move {  // UNBOUNDED SPAWN
        let mut count = 0u64;

        while let Some(bootstrap_event) = bootstrap_rx.recv().await {
            count += 1;

            match continuous_query_ref.process_source_change(bootstrap_event.change).await {
                Ok(results) => {
                    if !results.is_empty() {
                        // ... emit results ...
                    }
                }
                Err(e) => {
                    error!("Failed to process bootstrap event: {}", e);
                }
            }
        }
    });
}

// Plus event processor task (line 575)
let handle = tokio::spawn(async move {
    info!("Query '{}' starting priority queue event processor", query_id);

    loop {
        if !matches!(*status.read().await, ComponentStatus::Running) {
            break;
        }

        let source_event_wrapper = priority_queue.dequeue().await;  // Blocks waiting

        // ... process event ...
    }
});
```

### Performance Impact

- **Task proliferation**: N sources = N bootstrap tasks + 1 processor = N+1 tasks per query
- **With 50 sources Ã— 100 queries = 5,000+ background tasks** just for bootstrap
- **Executor starvation**: Tokio runtime may have fewer CPUs than tasks; scheduler contention
- **Memory overhead**: Each task has ~64KB stack + tokio overhead = ~320MB for 5000 tasks
- **Blocking dequeue**: `priority_queue.dequeue()` blocks indefinitely if queue is empty, ties up executor thread

### Suggested Optimization

1. **Use semaphore/bounded concurrency**: Limit concurrent bootstrap tasks
2. **Use single processor task with multiplexing**: Handle multiple sources in one task
3. **Batch processing**: Collect events before processing

```rust
// Better: Use semaphore to limit concurrency
use tokio::sync::Semaphore;

pub struct DrasiQuery {
    // ... existing fields ...
    bootstrap_semaphore: Arc<Semaphore>,  // Limit concurrent bootstraps
}

impl DrasiQuery {
    pub fn new(config: QueryConfig, event_tx: ComponentEventSender, ...) -> Result<Self> {
        let bootstrap_semaphore = Arc::new(Semaphore::new(4));  // Max 4 concurrent
        // ...
    }
}

// In start():
for (source_id, bootstrap_rx) in bootstrap_channels {
    let semaphore = self.bootstrap_semaphore.clone();

    tokio::spawn(async move {
        let _permit = semaphore.acquire().await.unwrap();  // Limit concurrency

        while let Some(event) = bootstrap_rx.recv().await {
            // ... process ...
        }
    });
}

// Better: Use select! for multiplexing
let mut bootstrap_tasks = vec![];
for (source_id, bootstrap_rx) in bootstrap_channels {
    bootstrap_tasks.push((source_id, Box::pin(bootstrap_rx)));
}

// Single task processes all sources
tokio::spawn(async move {
    while !bootstrap_tasks.is_empty() {
        match select!(...) {  // Multiplex all tasks
            Some((source_id, event)) => {
                // Process event from any source
            }
        }
    }
});
```

---

## Summary Table

| Issue | Severity | Location | Frequency | Per-Event Impact |
|-------|----------|----------|-----------|-----------------|
| RwLock in result set | HIGH | manager.rs 690-732 | Every event | Lock acquire + Vec clone |
| HashMap clones | MEDIUM-HIGH | manager.rs, sources/manager.rs | Per list/start/stop | ~1KB allocation |
| O(n) Vec ops | MEDIUM | manager.rs 703-720 | Per update/delete | O(n) scan |
| String allocations | MEDIUM | Throughout | Every event | 10+ string allocs |
| Multiple lock acqs | MEDIUM | manager.rs 296-340 | Per lifecycle op | 2-4 lock acquires |
| Unbounded tasks | MEDIUM | manager.rs 451+ | Per source | +1 task per source |

---

## Recommended Action Plan

### Phase 1: Quick Wins (1-2 hours)
1. Replace `.to_string()` with `&'static str` for literal strings
2. Use string interning for common metadata keys
3. Extract intermediate lock acquisitions in manager methods

### Phase 2: Medium Term (1-2 days)
1. Replace result set `Vec` with `IndexMap` for O(1) operations
2. Implement proper number-to-JSON conversion (avoid string conversions)
3. Add semaphore for bootstrap task concurrency limiting

### Phase 3: Long Term (1+ weeks)
1. Consider lock-free data structure for result set (DashMap)
2. Refactor manager iteration patterns to avoid HashMap clones
3. Implement event batching in query processor

---

## Testing Approach

### Benchmark Suite
```bash
# Monitor lock contention
cargo bench --bench query_throughput

# Profile memory allocations
valgrind --tool=massif ./target/release/drasi-server-core --test

# Flame graph analysis
perf record -F 99 ./target/release/test-app && perf script | stackcollapse-perf.pl | flamegraph.pl > perf.svg
```

### Load Test Scenarios
- 1000 events/sec from single source through query
- 100 events/sec across 10 sources (fanout)
- 10,000-item result set with 50% update/delete ratio
- 50 concurrent queries on 5 sources

